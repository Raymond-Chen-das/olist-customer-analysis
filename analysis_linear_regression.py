# ====================================================
# å¤šå…ƒç·šæ€§å›æ­¸åˆ†æ (Multiple Linear Regression)
# æ¢è¨å½±éŸ¿æ¶ˆè²»é‡‘é¡çš„å¤šè®Šé‡å› ç´ 
# ====================================================
import os
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
matplotlib.rcParams['axes.unicode_minus'] = False

# è¼‰å…¥å…±ç”¨è³‡æ–™æ¨¡çµ„
from data_preparation import load_and_prepare_data, get_output_folder

print("="*60)
print("ğŸ“Š å¤šå…ƒç·šæ€§å›æ­¸åˆ†æ (Multiple Linear Regression)")
print("="*60)

# è¼‰å…¥è³‡æ–™
customer_features = load_and_prepare_data()
output_folder = get_output_folder()

# ====================================================
# 1. æº–å‚™è³‡æ–™
# ====================================================

print("\n" + "="*60)
print("ğŸ“ˆ 1. è³‡æ–™æº–å‚™")
print("="*60)

# é¸æ“‡é æ¸¬è®Šé …
X_cols = ['avg_delay_days', 'avg_freight_ratio', 'avg_review_score',
          'avg_payment_installments', 'avg_item_count']

X = customer_features[X_cols].copy()
y = customer_features['avg_order_value'].copy()

# ç§»é™¤éºæ¼å€¼
valid_idx = ~(X.isna().any(axis=1) | y.isna())
X = X[valid_idx]
y = y[valid_idx]

print(f"æœ‰æ•ˆæ¨£æœ¬æ•¸: {len(y):,}")
print(f"ä¾è®Šé …: å¹³å‡æ¶ˆè²»é‡‘é¡ (avg_order_value)")
print(f"è‡ªè®Šé …: {X_cols}")

# ====================================================
# 2. æª¢æŸ¥å¤šå…ƒå…±ç·šæ€§ (VIF)
# ====================================================

print("\n" + "="*60)
print("ğŸ“ˆ 2. å¤šå…ƒå…±ç·šæ€§æª¢æ¸¬ (Variance Inflation Factor)")
print("="*60)

X_with_const = sm.add_constant(X)

vif_data = pd.DataFrame()
vif_data['è®Šé …'] = X.columns
vif_data['VIF'] = [variance_inflation_factor(X_with_const.values, i+1) for i in range(len(X.columns))]

print("\nğŸ“Š VIF å€¼ (VIF > 10 è¡¨ç¤ºåš´é‡å…±ç·šæ€§):")
print(vif_data.to_string(index=False))

if (vif_data['VIF'] > 10).any():
    print("\nâš ï¸ è­¦å‘Š: å­˜åœ¨åš´é‡å¤šå…ƒå…±ç·šæ€§å•é¡Œï¼")
else:
    print("\nâœ… ç„¡åš´é‡å¤šå…ƒå…±ç·šæ€§å•é¡Œ")

# ====================================================
# 3. å»ºç«‹ OLS å›æ­¸æ¨¡å‹
# ====================================================

print("\n" + "="*60)
print("ğŸ“ˆ 3. å¤šå…ƒç·šæ€§å›æ­¸æ¨¡å‹ (OLS)")
print("="*60)

# åŠ å…¥å¸¸æ•¸é …
X_const = sm.add_constant(X)

# å»ºç«‹æ¨¡å‹
model_ols = sm.OLS(y, X_const).fit()

print("\n" + "="*50)
print("OLS å›æ­¸çµæœæ‘˜è¦")
print("="*50)
print(model_ols.summary())

# ====================================================
# 4. å›æ­¸ä¿‚æ•¸è§£è®€
# ====================================================

print("\n" + "="*60)
print("ğŸ“Š 4. å›æ­¸ä¿‚æ•¸è§£è®€")
print("="*60)

coef_df = pd.DataFrame({
    'è®Šé …': ['æˆªè· (Intercept)'] + X_cols,
    'ä¿‚æ•¸ (B)': model_ols.params.values,
    'æ¨™æº–èª¤ (SE)': model_ols.bse.values,
    't å€¼': model_ols.tvalues.values,
    'p å€¼': model_ols.pvalues.values,
    '95% CI ä¸‹ç•Œ': model_ols.conf_int()[0].values,
    '95% CI ä¸Šç•Œ': model_ols.conf_int()[1].values
})

coef_df['é¡¯è‘—æ€§'] = coef_df['p å€¼'].apply(
    lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''
)

# è¨ˆç®—æ¨™æº–åŒ–ä¿‚æ•¸ (Beta)
X_std = (X - X.mean()) / X.std()
X_std_const = sm.add_constant(X_std)
model_std = sm.OLS((y - y.mean()) / y.std(), X_std_const).fit()
coef_df['æ¨™æº–åŒ–ä¿‚æ•¸ (Î²)'] = [np.nan] + list(model_std.params.values[1:])

print("\nğŸ“Š å›æ­¸ä¿‚æ•¸è¡¨:")
print(coef_df.to_string(index=False))

print(f"\nğŸ“ˆ æ¨¡å‹é…é©åº¦:")
print(f"RÂ² = {model_ols.rsquared:.4f}")
print(f"Adjusted RÂ² = {model_ols.rsquared_adj:.4f}")
print(f"F-statistic = {model_ols.fvalue:.2f}")
print(f"F-test p-value = {model_ols.f_pvalue:.4e}")

# ====================================================
# 5. æ®˜å·®è¨ºæ–·
# ====================================================

print("\n" + "="*60)
print("ğŸ“ˆ 5. æ®˜å·®è¨ºæ–·")
print("="*60)

# é æ¸¬å€¼èˆ‡æ®˜å·®
y_pred = model_ols.predict(X_const)
residuals = model_ols.resid

print(f"æ®˜å·®å¹³å‡å€¼: {residuals.mean():.6f} (æ‡‰æ¥è¿‘ 0)")
print(f"æ®˜å·®æ¨™æº–å·®: {residuals.std():.4f}")

# Durbin-Watson æª¢å®š (è‡ªç›¸é—œ)
from statsmodels.stats.stattools import durbin_watson
dw = durbin_watson(residuals)
print(f"Durbin-Watson çµ±è¨ˆé‡: {dw:.4f} (æ¥è¿‘ 2 è¡¨ç¤ºç„¡è‡ªç›¸é—œ)")

# ====================================================
# 6. æ¨¡å‹é æ¸¬èƒ½åŠ›è©•ä¼°
# ====================================================

print("\n" + "="*60)
print("ğŸ“ˆ 6. æ¨¡å‹é æ¸¬èƒ½åŠ›è©•ä¼° (äº¤å‰é©—è­‰)")
print("="*60)

# åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# sklearn ç·šæ€§å›æ­¸
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_test = lr_model.predict(X_test)

# è©•ä¼°æŒ‡æ¨™
r2_test = r2_score(y_test, y_pred_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
mae = mean_absolute_error(y_test, y_pred_test)

print(f"è¨“ç·´é›† RÂ²: {lr_model.score(X_train, y_train):.4f}")
print(f"æ¸¬è©¦é›† RÂ²: {r2_test:.4f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAE: {mae:.2f}")

# ====================================================
# 7. è¦–è¦ºåŒ–
# ====================================================

print("\n" + "="*60)
print("ğŸ“Š 7. ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨")
print("="*60)

# 7.1 å›æ­¸ä¿‚æ•¸åœ–
coef_plot = coef_df[coef_df['è®Šé …'] != 'æˆªè· (Intercept)'].copy()
coef_plot['è®Šé …ä¸­æ–‡'] = ['å»¶é²å¤©æ•¸', 'é‹è²»æ¯”ä¾‹', 'è©•è«–åˆ†æ•¸', 'åˆ†æœŸæœŸæ•¸', 'å¹³å‡å•†å“æ•¸']

fig_coef = go.Figure()

# æ·»åŠ ä¿‚æ•¸èˆ‡ä¿¡è³´å€é–“
fig_coef.add_trace(go.Bar(
    x=coef_plot['è®Šé …ä¸­æ–‡'],
    y=coef_plot['ä¿‚æ•¸ (B)'],
    marker_color=['#FF6B6B' if c < 0 else '#4ECDC4' for c in coef_plot['ä¿‚æ•¸ (B)']],
    text=[f"{c:.2f}{s}" for c, s in zip(coef_plot['ä¿‚æ•¸ (B)'], coef_plot['é¡¯è‘—æ€§'])],
    textposition='outside',
    error_y=dict(
        type='data',
        symmetric=False,
        array=coef_plot['95% CI ä¸Šç•Œ'] - coef_plot['ä¿‚æ•¸ (B)'],
        arrayminus=coef_plot['ä¿‚æ•¸ (B)'] - coef_plot['95% CI ä¸‹ç•Œ']
    )
))

fig_coef.update_layout(
    title=f'<b>ç·šæ€§å›æ­¸ä¿‚æ•¸ (ä¾è®Šé …ï¼šå¹³å‡æ¶ˆè²»é‡‘é¡)</b><br><sub>RÂ² = {model_ols.rsquared:.4f}, Adj. RÂ² = {model_ols.rsquared_adj:.4f}</sub>',
    xaxis_title='é æ¸¬è®Šé …',
    yaxis_title='å›æ­¸ä¿‚æ•¸ (B)',
    height=500,
    template='plotly_white'
)

output_coef = os.path.join(output_folder, 'regression_coefficients.html')
fig_coef.write_html(output_coef)
print(f"âœ… å›æ­¸ä¿‚æ•¸åœ–å·²å„²å­˜: {output_coef}")

# 7.2 æ¨™æº–åŒ–ä¿‚æ•¸åœ–
fig_beta = go.Figure()

beta_values = coef_plot['æ¨™æº–åŒ–ä¿‚æ•¸ (Î²)'].values
fig_beta.add_trace(go.Bar(
    x=coef_plot['è®Šé …ä¸­æ–‡'],
    y=beta_values,
    marker_color=['#FF6B6B' if c < 0 else '#4ECDC4' for c in beta_values],
    text=[f"Î²={b:.3f}{s}" for b, s in zip(beta_values, coef_plot['é¡¯è‘—æ€§'])],
    textposition='outside'
))

fig_beta.update_layout(
    title='<b>æ¨™æº–åŒ–å›æ­¸ä¿‚æ•¸ (Beta)</b><br><sub>å¯æ¯”è¼ƒå„è®Šé …çš„ç›¸å°é‡è¦æ€§</sub>',
    xaxis_title='é æ¸¬è®Šé …',
    yaxis_title='æ¨™æº–åŒ–ä¿‚æ•¸ (Î²)',
    height=500,
    template='plotly_white'
)

output_beta = os.path.join(output_folder, 'regression_beta.html')
fig_beta.write_html(output_beta)
print(f"âœ… æ¨™æº–åŒ–ä¿‚æ•¸åœ–å·²å„²å­˜: {output_beta}")

# 7.3 æ®˜å·®è¨ºæ–·åœ–
fig_resid = make_subplots(
    rows=2, cols=2,
    subplot_titles=['æ®˜å·® vs é æ¸¬å€¼', 'æ®˜å·®ç›´æ–¹åœ–', 'Q-Q åœ–', 'æ®˜å·®åˆ†å¸ƒ']
)

# æ®˜å·® vs é æ¸¬å€¼
sample_idx = np.random.choice(len(y_pred), min(5000, len(y_pred)), replace=False)
fig_resid.add_trace(
    go.Scatter(
        x=y_pred.iloc[sample_idx] if hasattr(y_pred, 'iloc') else y_pred[sample_idx],
        y=residuals.iloc[sample_idx] if hasattr(residuals, 'iloc') else residuals[sample_idx],
        mode='markers',
        marker=dict(size=4, opacity=0.5, color='#4ECDC4'),
        showlegend=False
    ),
    row=1, col=1
)
fig_resid.add_hline(y=0, line_dash="dash", line_color="red", row=1, col=1)

# æ®˜å·®ç›´æ–¹åœ–
fig_resid.add_trace(
    go.Histogram(x=residuals, nbinsx=50, marker_color='#4ECDC4', showlegend=False),
    row=1, col=2
)

# Q-Q åœ–
from scipy import stats
(osm, osr), (slope, intercept, r) = stats.probplot(residuals, dist="norm")
fig_resid.add_trace(
    go.Scatter(x=osm, y=osr, mode='markers', marker=dict(size=4, color='#4ECDC4'), showlegend=False),
    row=2, col=1
)
fig_resid.add_trace(
    go.Scatter(x=osm, y=slope*np.array(osm)+intercept, mode='lines',
               line=dict(color='red', dash='dash'), showlegend=False),
    row=2, col=1
)

# æ®˜å·®åˆ†å¸ƒ (Box plot)
fig_resid.add_trace(
    go.Box(y=residuals, marker_color='#4ECDC4', showlegend=False),
    row=2, col=2
)

fig_resid.update_layout(
    title='<b>æ®˜å·®è¨ºæ–·åœ–</b>',
    height=700,
    template='plotly_white'
)

fig_resid.update_xaxes(title_text='é æ¸¬å€¼', row=1, col=1)
fig_resid.update_yaxes(title_text='æ®˜å·®', row=1, col=1)
fig_resid.update_xaxes(title_text='æ®˜å·®', row=1, col=2)
fig_resid.update_yaxes(title_text='é »ç‡', row=1, col=2)
fig_resid.update_xaxes(title_text='ç†è«–åˆ†ä½æ•¸', row=2, col=1)
fig_resid.update_yaxes(title_text='æ¨£æœ¬åˆ†ä½æ•¸', row=2, col=1)

output_resid = os.path.join(output_folder, 'regression_diagnostics.html')
fig_resid.write_html(output_resid)
print(f"âœ… æ®˜å·®è¨ºæ–·åœ–å·²å„²å­˜: {output_resid}")

# ====================================================
# 8. åˆ†ææ‘˜è¦
# ====================================================

print("\n" + "="*60)
print("ğŸ“‹ åˆ†ææ‘˜è¦")
print("="*60)

summary = f"""
{'='*70}
å¤šå…ƒç·šæ€§å›æ­¸åˆ†æå ±å‘Š
{'='*70}

ğŸ“Š ç ”ç©¶å•é¡Œ
-------------------
æ¢è¨å“ªäº›å› ç´ æœƒå½±éŸ¿é¡§å®¢çš„å¹³å‡æ¶ˆè²»é‡‘é¡ï¼Ÿ

ğŸ“ˆ æ¨¡å‹è¨­å®š
-------------------
ä¾è®Šé … (Y): å¹³å‡æ¶ˆè²»é‡‘é¡ (avg_order_value)
è‡ªè®Šé … (X):
  - å¹³å‡å»¶é²å¤©æ•¸ (avg_delay_days)
  - å¹³å‡é‹è²»æ¯”ä¾‹ (avg_freight_ratio)
  - å¹³å‡è©•è«–åˆ†æ•¸ (avg_review_score)
  - å¹³å‡åˆ†æœŸæœŸæ•¸ (avg_payment_installments)
  - å¹³å‡å•†å“æ•¸é‡ (avg_item_count)

æ¨£æœ¬æ•¸: {len(y):,}

ğŸ“Š æ¨¡å‹é…é©åº¦
-------------------
RÂ² = {model_ols.rsquared:.4f} (è§£é‡‹ {model_ols.rsquared*100:.1f}% çš„è®Šç•°)
Adjusted RÂ² = {model_ols.rsquared_adj:.4f}
F-statistic = {model_ols.fvalue:.2f}, p-value = {model_ols.f_pvalue:.4e}

ğŸ“ˆ å›æ­¸ä¿‚æ•¸çµæœ
-------------------
{coef_df.to_string(index=False)}

ğŸ” é¡¯è‘—é æ¸¬è®Šé …è§£è®€
-------------------
"""

# æ‰¾å‡ºé¡¯è‘—çš„é æ¸¬è®Šé …
sig_vars = coef_df[(coef_df['é¡¯è‘—æ€§'] != '') & (coef_df['è®Šé …'] != 'æˆªè· (Intercept)')]
for _, row in sig_vars.iterrows():
    direction = "æ­£å‘" if row['ä¿‚æ•¸ (B)'] > 0 else "è² å‘"
    summary += f"- {row['è®Šé …']}: {direction}å½±éŸ¿ (B = {row['ä¿‚æ•¸ (B)']:.3f}, p < 0.05)\n"

summary += f"""
ğŸ“Š äº¤å‰é©—è­‰çµæœ
-------------------
è¨“ç·´é›† RÂ²: {lr_model.score(X_train, y_train):.4f}
æ¸¬è©¦é›† RÂ²: {r2_test:.4f}
RMSE: {rmse:.2f}
MAE: {mae:.2f}

ğŸ“Š å¤šå…ƒå…±ç·šæ€§æª¢æ¸¬ (VIF)
-------------------
{vif_data.to_string(index=False)}

ğŸ“ è¼¸å‡ºæª”æ¡ˆ
-------------------
âœ… {output_coef}
âœ… {output_beta}
âœ… {output_resid}

{'='*70}
"""

print(summary)

# å„²å­˜å ±å‘Š
report_path = os.path.join(output_folder, 'regression_report.txt')
with open(report_path, 'w', encoding='utf-8') as f:
    f.write(summary)

print(f"ğŸ“„ å ±å‘Šå·²å„²å­˜: {report_path}")
print("\nğŸ‰ å¤šå…ƒç·šæ€§å›æ­¸åˆ†æå®Œæˆï¼")
